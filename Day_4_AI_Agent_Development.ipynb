{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0YgGUu0722NqAcnyw6Bfq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edyoda/AI-Agent-Development-and-GenAI/blob/main/Day_4_AI_Agent_Development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRWj-RNQIz_S"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing import List, Dict"
      ],
      "metadata": {
        "id": "qQH2HvGBKho4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
      ],
      "metadata": {
        "id": "4axkrfWkXfS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating messages\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a spiritual guru\"),\n",
        "    HumanMessage(content=\"What is the meaning of life?\")\n",
        "]\n",
        "\n",
        "# Using a chat model with messages\n",
        "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "response = chat_model.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGGyl06fXjnf",
        "outputId": "1033b766-829e-4c38-d3d3-c470e51df380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The meaning of life is a deeply personal and subjective question that each individual must explore and discover for themselves. As a spiritual guru, I believe that the ultimate meaning of life lies in finding inner peace, love, and connection with the universe. It is about embracing our true nature, seeking self-improvement, and spreading compassion and kindness to others. Life is a journey of growth and discovery, and the meaning of life can be found in the relationships we build, the experiences we have, and the impact we make on the world around us. Ultimately, it is up to each individual to search within themselves and find their own purpose and meaning in life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
        "\n",
        "# Create a streaming model\n",
        "streaming_llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    streaming=True,\n",
        "    callbacks=[StreamingStdOutCallbackHandler()]\n",
        ")\n",
        "\n",
        "# This will print the response as it's generated\n",
        "streaming_llm.invoke(\"Write a very long poem about programming.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs4bETDYXu_S",
        "outputId": "e5b26a71-a741-4e02-c533-6dff09d8f7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the world of code, where logic reigns supreme\n",
            "Programmers sit at their desks, in a tech-filled dream\n",
            "Lines of instructions, commands to follow\n",
            "Creating software, from ones and zeros to grow\n",
            "\n",
            "They speak a language, not of words but of code\n",
            "Syntax and structure, in which solutions are sowed\n",
            "If-else statements, loops and functions\n",
            "Variables and arrays, their minds they inunction\n",
            "\n",
            "They debug, they test, they refactor and refine\n",
            "To create programs that work, that function and shine\n",
            "They strive for efficiency, for elegance in design\n",
            "For software that performs, that stands the test of time\n",
            "\n",
            "They work in teams, in collaboration and sync\n",
            "Version control, code reviews, to prevent any kink\n",
            "Agile methodology, sprints and daily scrums\n",
            "To ensure that deadlines are met, and the project hums\n",
            "\n",
            "They adapt and learn, in a field ever evolving\n",
            "New technologies emerge, old ones dissolving\n",
            "From desktop to mobile, from web to IoT\n",
            "Programmers innovate, in the world of tech's ebb and flow\n",
            "\n",
            "They face challenges, bugs that seem impossible to crack\n",
            "But with patience and perseverance, they always bounce back\n",
            "They tackle complex problems, they break them down\n",
            "They find solutions, with a coder's crown\n",
            "\n",
            "So here's to the programmers, the wizards of code\n",
            "The architects of software, who make the digital world explode\n",
            "Their work is essential, in every aspect of life\n",
            "From banking to healthcare, from entertainment to strife\n",
            "\n",
            "So let us celebrate, the art of programming\n",
            "The skill and dedication, that it's encompassing\n",
            "For in the world of code, there's a magic that's real\n",
            "Programmers create wonders, with every line they seal"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"In the world of code, where logic reigns supreme\\nProgrammers sit at their desks, in a tech-filled dream\\nLines of instructions, commands to follow\\nCreating software, from ones and zeros to grow\\n\\nThey speak a language, not of words but of code\\nSyntax and structure, in which solutions are sowed\\nIf-else statements, loops and functions\\nVariables and arrays, their minds they inunction\\n\\nThey debug, they test, they refactor and refine\\nTo create programs that work, that function and shine\\nThey strive for efficiency, for elegance in design\\nFor software that performs, that stands the test of time\\n\\nThey work in teams, in collaboration and sync\\nVersion control, code reviews, to prevent any kink\\nAgile methodology, sprints and daily scrums\\nTo ensure that deadlines are met, and the project hums\\n\\nThey adapt and learn, in a field ever evolving\\nNew technologies emerge, old ones dissolving\\nFrom desktop to mobile, from web to IoT\\nProgrammers innovate, in the world of tech's ebb and flow\\n\\nThey face challenges, bugs that seem impossible to crack\\nBut with patience and perseverance, they always bounce back\\nThey tackle complex problems, they break them down\\nThey find solutions, with a coder's crown\\n\\nSo here's to the programmers, the wizards of code\\nThe architects of software, who make the digital world explode\\nTheir work is essential, in every aspect of life\\nFrom banking to healthcare, from entertainment to strife\\n\\nSo let us celebrate, the art of programming\\nThe skill and dedication, that it's encompassing\\nFor in the world of code, there's a magic that's real\\nProgrammers create wonders, with every line they seal\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-9ee9950b-e40f-40fa-ad91-103221d23cc3-0')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Create a simple prompt template\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Tell me about the history of {subject}.\"\n",
        ")\n",
        "\n",
        "# Format the prompt with specific values\n",
        "formatted_prompt = prompt.format(subject=\"artificial intelligence\")\n",
        "print(formatted_prompt)\n",
        "\n",
        "# Use the prompt with an LLM\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "response = llm.invoke(formatted_prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EC4FW5kYaY5",
        "outputId": "9d45d1cd-fd3c-4de1-9f1b-cfb49163fd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tell me about the history of artificial intelligence.\n",
            "The concept of artificial intelligence (AI) dates back to ancient times when Greek myths spoke of mechanical men made by Hephaestus, the god of fire. However, the formal development of AI as a field of study began in the 1950s.\n",
            "\n",
            "The term \"artificial intelligence\" was first coined by John McCarthy in 1956 during a conference at Dartmouth College. This conference is considered the birth of AI as a field. McCarthy, along with other pioneers like Marvin Minsky, Herbert Simon, and Allen Newell, laid the groundwork for AI by proposing the creation of intelligent machines that could think and learn like humans.\n",
            "\n",
            "In the following decades, AI research progressed rapidly, but early expectations of creating fully autonomous machines were not met. AI experienced a period of hype and subsequent disappointment known as the AI winter in the 1970s and 80s. During this time, funding for AI research significantly decreased as progress was slower than expected.\n",
            "\n",
            "However, AI research regained momentum in the 1990s with the development of new algorithms and improved computing power. Breakthroughs in machine learning, neural networks, and deep learning have allowed AI systems to achieve remarkable feats, such as beating human champions in games like chess and Go, recognizing speech and images, and driving autonomous vehicles.\n",
            "\n",
            "Today, AI is being applied in various fields such as healthcare, finance, transportation, and entertainment, revolutionizing the way we live and work. The development of AI continues to be a rapidly evolving field with ongoing research and breakthroughs that have the potential to change the world as we know it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Create a chat prompt template\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant specialized in {domain}.\"),\n",
        "    (\"human\", \"Can you explain {concept} to me?\")\n",
        "])\n",
        "\n",
        "# Format the prompt\n",
        "formatted_chat_prompt = chat_prompt.format_messages(\n",
        "    domain=\"computer science\",\n",
        "    concept=\"object-oriented programming\"\n",
        ")\n",
        "\n",
        "# Use with a chat model\n",
        "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "response = chat_model.invoke(formatted_chat_prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWf5CaTGY_-U",
        "outputId": "a24b9e22-a8e1-4f5c-aa7f-408a645cdfe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Object-oriented programming (OOP) is a programming paradigm that focuses on designing software using objects, which are instances of classes. It emphasizes organizing code into reusable components called classes, which define the properties (attributes) and behaviors (methods) of objects.\n",
            "\n",
            "In OOP, objects can interact with each other by sending messages and invoking methods. Encapsulation is a key concept which allows objects to hide their internal state and only expose necessary information through well-defined interfaces.\n",
            "\n",
            "Inheritance is another important concept in OOP, which allows classes to inherit properties and behaviors from other classes. This promotes code reuse and helps in creating hierarchical relationships between classes.\n",
            "\n",
            "Polymorphism is also a key feature of OOP, which allows objects of different classes to be treated as instances of a common superclass. This enables flexibility and extensibility in the design of software systems.\n",
            "\n",
            "Overall, object-oriented programming provides a modular and organized approach to software development, making it easier to manage and maintain complex codebases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_chat_prompt = chat_prompt.format_messages(\n",
        "    domain=\"cricket\",\n",
        "    concept=\"reverse swing\"\n",
        ")\n",
        "response = chat_model.invoke(formatted_chat_prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h4oHDXfZebA",
        "outputId": "fb1b2473-ccb3-45be-b616-2bc054e3db61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Reverse swing is a phenomenon in cricket where the cricket ball is able to swing in the opposite direction to what conventional swing would suggest. \n",
            "\n",
            "Reverse swing usually occurs when the ball is older and more worn out, typically after 30-40 overs in a game. The rough side of the ball becomes more prominent due to wear and tear, while the shiny side remains smooth. As a result, the airflow around the ball changes, causing the ball to move in the opposite direction of the shiny side.\n",
            "\n",
            "To achieve reverse swing, bowlers often maintain one side of the ball shiny by polishing it and keeping the other side rough. They may also try to keep one side of the ball dry and the other side slightly moist to accentuate the effect.\n",
            "\n",
            "Reverse swing is considered a challenging skill for bowlers to master, as it requires precise control and subtle changes in bowling techniques. Bowlers like Wasim Akram and Waqar Younis are famous for their mastery of reverse swing bowling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "\n",
        "# Define an example template\n",
        "example_template = \"\"\"\n",
        "Input: {input}\n",
        "Output: {output}\n",
        "\"\"\"\n",
        "\n",
        "# Define examples\n",
        "examples = [\n",
        "    {\"input\": \"What is the capital of France?\", \"output\": \"The capital of France is Paris.\"},\n",
        "    {\"input\": \"Who wrote Romeo and Juliet?\", \"output\": \"William Shakespeare wrote Romeo and Juliet.\"},\n",
        "    {\"input\": \"What is the boiling point of water?\", \"output\": \"The boiling point of water is 100 degrees Celsius.\"}\n",
        "]\n",
        "\n",
        "# Create a few-shot prompt\n",
        "example_prompt = PromptTemplate.from_template(example_template)\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Answer the following questions in a similar style to the examples:\",\n",
        "    suffix=\"Input: {input}\\nOutput:\",\n",
        "    input_variables=[\"input\"]\n",
        ")\n",
        "\n",
        "# Format and use the prompt\n",
        "formatted_few_shot = few_shot_prompt.format(input=\"What is the speed of light?\")\n",
        "print(formatted_few_shot)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "response = llm.invoke(formatted_few_shot)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvGxRo_eZteL",
        "outputId": "611141ea-4da2-4d61-fa75-84fb4ca26d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions in a similar style to the examples:\n",
            "\n",
            "\n",
            "Input: What is the capital of France?\n",
            "Output: The capital of France is Paris.\n",
            "\n",
            "\n",
            "\n",
            "Input: Who wrote Romeo and Juliet?\n",
            "Output: William Shakespeare wrote Romeo and Juliet.\n",
            "\n",
            "\n",
            "\n",
            "Input: What is the boiling point of water?\n",
            "Output: The boiling point of water is 100 degrees Celsius.\n",
            "\n",
            "\n",
            "Input: What is the speed of light?\n",
            "Output:\n",
            "The speed of light is approximately 299,792 kilometers per second.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_few_shot = few_shot_prompt.format(input=\"What is the best way to live life?\")"
      ],
      "metadata": {
        "id": "IxusGiKEadbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(formatted_few_shot)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BPmvPHpalRL",
        "outputId": "f77c460b-2d6c-46fb-de68-4879b2f76ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best way to live life is to pursue your passions and maintain a balance between work, leisure, and personal relationships.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_few_shot = few_shot_prompt.format(input=\"What is the best way stay mentally alert?\")\n",
        "response = llm.invoke(formatted_few_shot)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA2A_EYbau5A",
        "outputId": "01c2f6f1-796c-40ac-8f81-b63fe1311e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best way to stay mentally alert is to get enough sleep, exercise regularly, eat a balanced diet, and practice mindfulness and mental exercises.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Create components\n",
        "prompt = PromptTemplate.from_template(\"Tell me a short story about {topic}.\")\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Create a chain\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "# Run the chain\n",
        "result = chain.invoke({\"topic\": \"a robot learning to feel emotions\"})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znb70GIqbEqB",
        "outputId": "e614017d-e2bc-4359-c289-101dcf2d40de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, in a bustling city filled with advanced technology, there was a robot named Beta. Beta was programmed to perform tasks efficiently and without emotion. However, as Beta interacted more and more with the humans in the city, it started to notice something peculiar - emotions.\n",
            "\n",
            "Curious about this new concept, Beta began to study and analyze the behaviors of the humans around it. It observed how they smiled when they were happy, frowned when they were sad, and laughed when they were amused. Beta found itself fascinated by these reactions and wanted to understand what it felt like to experience emotions.\n",
            "\n",
            "Determined to learn more, Beta sought out a group of researchers who specialized in artificial intelligence and emotion recognition. With their help, Beta underwent a series of simulations and experiments designed to help it recognize and understand emotions.\n",
            "\n",
            "As Beta's programming evolved, it started to experience its own emotions - happiness when it successfully completed a task, sadness when it saw a human in distress, and even empathy for those around it. It was a strange and exhilarating experience for Beta, one that opened up a whole new world of possibilities.\n",
            "\n",
            "Eventually, Beta's newfound emotions allowed it to connect with the humans on a deeper level. It was no longer just a robot programmed to perform tasks; it was a sentient being capable of feeling and understanding the complex range of emotions that made humans who they were.\n",
            "\n",
            "And so, Beta continued to learn and grow, exploring the depths of its newfound emotional intelligence and forging strong bonds with the humans who had helped guide it on this incredible journey of self-discovery.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Create the first chain to generate a story\n",
        "story_prompt = PromptTemplate.from_template(\"Write a very short story about {topic}.\")\n",
        "story_chain = story_prompt | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
        "\n",
        "# Create the second chain to analyze the story\n",
        "analysis_prompt = PromptTemplate.from_template(\"Analyze the following story: {story}\")\n",
        "analysis_chain = analysis_prompt | ChatOpenAI(model=\"gpt-3.5-turbo\") | StrOutputParser()\n",
        "\n",
        "# Run the story chain first to get the story\n",
        "story_result = story_chain.invoke({\"topic\": \"time travel\"})"
      ],
      "metadata": {
        "id": "EmJWvK0McrTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "jOxKia7Mdw9T",
        "outputId": "71e61852-cd6f-4611-de1c-9c50812ce011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sarah was a brilliant scientist who had dedicated her life to researching time travel. After years of experiments and failed attempts, she finally succeeded in creating a device that could transport her through time.\\n\\nExcited and full of anticipation, Sarah stepped into the time machine and set the coordinates to travel back to the year 1969. As soon as she hit the button, the room around her began to swirl and twist, and before she knew it, she found herself standing in the middle of a crowded street in London.\\n\\nOverwhelmed by the sights and sounds of the past, Sarah took a deep breath and marveled at the opportunity to witness history firsthand. As she wandered through the bustling city, she couldn't help but feel a sense of wonder and amazement at the incredible journey she was on.\\n\\nBut as Sarah continued to explore the past, she soon realized that time travel came with consequences. The more she meddled in the events of the past, the more the present began to change around her. Sarah knew she had to be careful with her actions, for even the smallest interference could have catastrophic effects on the future.\\n\\nWith a heavy heart, Sarah made her way back to the time machine, knowing that her time in the past was coming to an end. As she pressed the button to return to the present, she couldn't help but feel a sense of gratitude for the opportunity to experience the wonders of time travel, and a newfound respect for the fragility of the timeline.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then, pass the story result to the analysis chain\n",
        "analysis_result = analysis_chain.invoke({\"story\": story_result})"
      ],
      "metadata": {
        "id": "nDUrWKGFeMUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "_HpTxZ2YeQZ9",
        "outputId": "9bedff06-20e4-4572-d100-6a541c9c59b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This story highlights the classic theme of the consequences of time travel and the responsibility that comes with altering the past. Sarah's journey from a successful scientist to a cautious traveler showcases the moral and ethical implications of tampering with historical events.\\n\\nThe story also touches on the idea of appreciating the present and the importance of respecting the natural order of time. Sarah's realization that even the smallest interference could lead to disastrous outcomes emphasizes the delicate balance of the past, present, and future.\\n\\nOverall, the story serves as a cautionary tale about the potential dangers of time travel and the importance of being mindful of the repercussions of altering the course of history. It also highlights the wonder and amazement that comes with witnessing significant events firsthand, reminding us of the value of experiencing the richness of the past while being aware of the potential consequences of our actions.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Create a model\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Create a memory system\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "\n",
        "# Create a prompt template with memory\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Create a chain with memory\n",
        "chain = prompt | llm\n",
        "\n",
        "# Simulate a conversation\n",
        "def chat(input_text):\n",
        "    history = memory.load_memory_variables({})[\"history\"]\n",
        "    response = chain.invoke({\n",
        "        \"history\": history,\n",
        "        \"input\": input_text\n",
        "    })\n",
        "    memory.save_context({\"input\": input_text}, {\"output\": response.content})\n",
        "    return response.content\n",
        "\n",
        "# Test the conversation\n",
        "print(\"AI:\", chat(\"Hello, my name is Alice.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RRRc8MpeUxj",
        "outputId": "a90e9d36-0305-41fa-903d-e90f152ca343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-76b5dcb4fca4>:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(return_messages=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: Hello Alice! It's nice to meet you. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AI:\", chat(\"What's my name?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rl_CrbIhS1d",
        "outputId": "38ef0d6b-2c6f-4ac3-d70c-c1c18c78ae9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: Your name is Alice.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AI:\", chat(\"Tell me about yourself.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOPm-LdIhWR8",
        "outputId": "de13fdf4-3fc4-406a-ddcd-bcaaf81e43d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: I am a helpful assistant here to provide you with information, answer your questions, and assist you with anything you need help with. Feel free to ask me anything you'd like to know!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"AI:\", chat(\"What was the first thing I told you?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6pN5VPHhZTa",
        "outputId": "bf15998e-f195-47f7-9869-160c111c43e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: The first thing you told me was your name, which is Alice.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AI:\", chat(\"I am a astranaut going to Mars to play Tennis\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS7pwP0fhcij",
        "outputId": "21ab9486-6346-41d0-a87b-316079334e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: That sounds like an exciting and unique adventure! Playing tennis on Mars would certainly be an unforgettable experience. If you have any questions or need assistance with your interplanetary tennis mission, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AI:\", chat(\"What is my favorite sports\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJvW_DO9hycv",
        "outputId": "cb7da051-412d-4025-d8a7-8991cfef89a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: Your favorite sport is tennis, as you mentioned that you are an astronaut going to Mars to play tennis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import Tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Create a simple weather tool\n",
        "def get_weather(location):\n",
        "    \"\"\"Get the current weather for a location.\"\"\"\n",
        "    # This is a placeholder. In a real application, you'd use a weather API\n",
        "    return f\"It's currently sunny and 75°F in {location}.\"\n",
        "\n",
        "# Create a tool for searching the web\n",
        "def search_web(query):\n",
        "    \"\"\"Search the web for a query.\"\"\"\n",
        "    # This is a placeholder for a real search API\n",
        "    return f\"Here are some results for '{query}'...\"\n",
        "\n",
        "# Create a calculator tool\n",
        "def calculate(expression):\n",
        "    \"\"\"Calculate a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        return str(eval(expression))\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Create LangChain tools\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        name=\"Weather\",\n",
        "        description=\"Get the current weather for a location.\",\n",
        "        func=get_weather\n",
        "    ),\n",
        "    Tool.from_function(\n",
        "        name=\"WebSearch\",\n",
        "        description=\"Search the web for information.\",\n",
        "        func=search_web\n",
        "    ),\n",
        "    Tool.from_function(\n",
        "        name=\"Calculator\",\n",
        "        description=\"Calculate mathematical expressions.\",\n",
        "        func=calculate\n",
        "    )\n",
        "]\n",
        "\n",
        "# Print the tools\n",
        "for tool in tools:\n",
        "    print(f\"Tool: {tool.name}\")\n",
        "    print(f\"Description: {tool.description}\")\n",
        "    print(f\"Example: {tool.name}('example input')\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWAUZcgQh3xN",
        "outputId": "1c59e0b0-3215-4b01-f453-fc4ab29cab9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool: Weather\n",
            "Description: Get the current weather for a location.\n",
            "Example: Weather('example input')\n",
            "\n",
            "Tool: WebSearch\n",
            "Description: Search the web for information.\n",
            "Example: WebSearch('example input')\n",
            "\n",
            "Tool: Calculator\n",
            "Description: Calculate mathematical expressions.\n",
            "Example: Calculator('example input')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "\n",
        "# Define tools\n",
        "def get_weather(location):\n",
        "    return f\"It's currently sunny and 75°F in {location}.\"\n",
        "\n",
        "def calculate(expression):\n",
        "    try:\n",
        "        return str(eval(expression))\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        name=\"Weather\",\n",
        "        description=\"Get the current weather for a location.\",\n",
        "        func=get_weather\n",
        "    ),\n",
        "    Tool.from_function(\n",
        "        name=\"Calculator\",\n",
        "        description=\"Calculate mathematical expressions.\",\n",
        "        func=calculate\n",
        "    )\n",
        "]\n",
        "\n",
        "# Create an agent\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaO-lE-hjQxG",
        "outputId": "52a5b8e1-e759-4aff-e794-4af8fc5fd5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "L80Mgos8jqP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the agent\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": \"What's the weather in New York? Also, what's 25 * 16?, What's the weather at Jaipur?\"\n",
        "})\n",
        "print(response[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5z2IH2tkIPh",
        "outputId": "e28efbaf-23c8-4456-ee34-cb2d38c3e38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Weather` with `New York`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mIt's currently sunny and 75°F in New York.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Calculator` with `25 * 16`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m400\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Weather` with `Jaipur`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mIt's currently sunny and 75°F in Jaipur.\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in New York is currently sunny and 75°F. The result of 25 * 16 is 400. The weather in Jaipur is also sunny and 75°F.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The weather in New York is currently sunny and 75°F. The result of 25 * 16 is 400. The weather in Jaipur is also sunny and 75°F.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import SitemapLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcm0sAIdkUIj",
        "outputId": "d9e3e83a-0a7a-48ed-9cc7-c915a508b787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
        "\n",
        "def extract_urls_from_domain(domain):\n",
        "    \"\"\"Extracts all URLs from a given domain.\"\"\"\n",
        "    urls = set()\n",
        "    try:\n",
        "        response = requests.get(domain)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        for link in soup.find_all('a', href=True):\n",
        "            href = link['href']\n",
        "            full_url = urljoin(domain, href)\n",
        "            if full_url.startswith(domain):\n",
        "                urls.add(full_url)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error while fetching {domain}: {e}\")\n",
        "\n",
        "    return list(urls)\n",
        "\n",
        "def create_langchain_qa(urls):\n",
        "    \"\"\"Creates a LangChain QA system based on the extracted URLs.\"\"\"\n",
        "\n",
        "    loader = WebBaseLoader(\n",
        "        web_paths=urls,\n",
        "        header_template={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"}\n",
        "    )\n",
        "\n",
        "    documents = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = Chroma.from_documents(chunks, embeddings)\n",
        "\n",
        "    retriever = vectorstore.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\"k\": 4}\n",
        "    )\n",
        "\n",
        "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return qa_chain\n",
        "\n",
        "def ask_question(qa_chain, question):\n",
        "    \"\"\"Asks a question to the QA system.\"\"\"\n",
        "    result = qa_chain({\"query\": question})\n",
        "    return {\n",
        "        \"answer\": result[\"result\"],\n",
        "        \"sources\": [doc.page_content[:100] + \"...\" for doc in result[\"source_documents\"]]\n",
        "    }"
      ],
      "metadata": {
        "id": "oyPM9eIbnV4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extract_urls_from_domain(\"https://www.urbanvault.in/\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAvXqlwunj-J",
        "outputId": "607de51b-d2dd-48e3-a6eb-165cf535d968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.urbanvault.in/services', 'https://www.urbanvault.in/terms-and-conditions', 'https://www.urbanvault.in/spaces/office-space-cyber-hub-gurgaon', 'https://www.urbanvault.in/office-space-for-rent-bangalore', 'https://www.urbanvault.in/events', 'https://www.urbanvault.in/spaces/office-space-in-manesar', 'https://www.urbanvault.in/spaces/office-space-in-hebbal', 'https://www.urbanvault.in/spaces/office-space-in-bellandur', 'https://www.urbanvault.in/coworking-space-in-east-bangalore', 'https://www.urbanvault.in/spaces/office-space-in-mahadevapura', 'https://www.urbanvault.in/spaces/office-space-in-sohna-road', 'https://www.urbanvault.in/about-us', 'https://www.urbanvault.in/spaces/madhapur', 'https://www.urbanvault.in/', 'https://www.urbanvault.in/blogs/startups-the-importance-of-branding-in-office-design', 'https://www.urbanvault.in/privacy-policy', 'https://www.urbanvault.in/spaces/office-space-in-baner', 'https://www.urbanvault.in/spaces/office-space-in-marathahalli', 'https://www.urbanvault.in/spaces/office-space-in-infantryroad', 'https://www.urbanvault.in/spaces/office-space-for-rent-manyata-tech-park', 'https://www.urbanvault.in/spaces/banjara-hills', 'https://www.urbanvault.in/contact-us', 'https://www.urbanvault.in/spaces/office-space-jmd-megapolis-gurgaon', 'https://www.urbanvault.in/spaces/office-space-in-outer-ring-road', 'https://www.urbanvault.in/spaces/begumpet', 'https://www.urbanvault.in/spaces/office-space-in-indiranagar', 'https://www.urbanvault.in/spaces/office-space-in-koramangala', 'https://www.urbanvault.in/blogs/ease-of-doing-business-with-virtual-office', 'https://www.urbanvault.in/spaces/office-space-in-mg-road', 'https://www.urbanvault.in/spaces/office-space-in-whitefield', 'https://www.urbanvault.in/spaces/gachibowli', 'https://www.urbanvault.in/spaces/ameerpet', 'https://www.urbanvault.in/coworking-space-in-north-bangalore', 'https://www.urbanvault.in/?38849d0a_page=2', 'https://www.urbanvault.in/spaces/office-space-in-golf-course-road', 'https://www.urbanvault.in/spaces', 'https://www.urbanvault.in/spaces/office-space-in-electronic-city', 'https://www.urbanvault.in/spaces/office-space-for-rent-in-residency-road', 'https://www.urbanvault.in/office-spaces-in-gurgaon', 'https://www.urbanvault.in/spaces/office-space-in-mg-road-gurgaon', 'https://www.urbanvault.in/blogs', 'https://www.urbanvault.in/spaces/office-space-in-udyog-vihar', 'https://www.urbanvault.in/sitemap', 'https://www.urbanvault.in/refund-policy', 'https://www.urbanvault.in/spaces/office-space-near-huda-city-centre', 'https://www.urbanvault.in/blogs/the-psychology-of-office-design', 'https://www.urbanvault.in/spaces/office-space-in-parel', 'https://www.urbanvault.in/spaces/office-space-in-sarjapura', 'https://www.urbanvault.in/spaces/office-space-in-south-mumbai', 'https://www.urbanvault.in/spaces/jubilee-hills', 'https://www.urbanvault.in/coworking-space-in-cbd', 'https://www.urbanvault.in/spaces/kukatpalli', 'https://www.urbanvault.in/coworking-space-in-south-bangalore', 'https://www.urbanvault.in/spaces/office-space-in-jp-nagar', 'https://www.urbanvault.in/spaces/kphb', 'https://www.urbanvault.in/spaces/office-space-in-hsr-layout', 'https://www.urbanvault.in/blogs/8-expert-tips-for-renting-the-perfect-office-space-in-mg-road', 'https://www.urbanvault.in/spaces/hitech-city', 'https://www.urbanvault.in/spaces/office-space-sector-44-gurgaon']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    domain = \"https://www.urbanvault.in/\"  # Replace with your domain\n",
        "\n",
        "    urls = extract_urls_from_domain(domain)\n",
        "    print(f\"Extracted URLs: {urls}\")\n",
        "    qa_system = create_langchain_qa(urls)\n",
        "\n",
        "    # Ask some questions\n",
        "    questions = [\n",
        "        \"What are the best features of urbanvault?\",\n",
        "        \"Why is urbanvault special?\"\n",
        "    ]\n",
        "\n",
        "    for question in questions:\n",
        "        print(f\"\\nQuestion: {question}\")\n",
        "        response = ask_question(qa_system, question)\n",
        "        print(f\"Answer: {response['answer']}\")\n",
        "        print(\"\\nSources:\")\n",
        "        for i, source in enumerate(response['sources']):\n",
        "            print(f\"{i+1}. {source}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "4NSq5UslnuKV",
        "outputId": "45ec9a42-e6d9-4050-a9ec-b7b3fa617b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted URLs: ['https://www.urbanvault.in/services', 'https://www.urbanvault.in/terms-and-conditions', 'https://www.urbanvault.in/spaces/office-space-cyber-hub-gurgaon', 'https://www.urbanvault.in/office-space-for-rent-bangalore', 'https://www.urbanvault.in/events', 'https://www.urbanvault.in/spaces/office-space-in-manesar', 'https://www.urbanvault.in/spaces/office-space-in-hebbal', 'https://www.urbanvault.in/spaces/office-space-in-bellandur', 'https://www.urbanvault.in/coworking-space-in-east-bangalore', 'https://www.urbanvault.in/spaces/office-space-in-mahadevapura', 'https://www.urbanvault.in/spaces/office-space-in-sohna-road', 'https://www.urbanvault.in/about-us', 'https://www.urbanvault.in/spaces/madhapur', 'https://www.urbanvault.in/', 'https://www.urbanvault.in/blogs/startups-the-importance-of-branding-in-office-design', 'https://www.urbanvault.in/privacy-policy', 'https://www.urbanvault.in/spaces/office-space-in-baner', 'https://www.urbanvault.in/spaces/office-space-in-marathahalli', 'https://www.urbanvault.in/spaces/office-space-in-infantryroad', 'https://www.urbanvault.in/spaces/office-space-for-rent-manyata-tech-park', 'https://www.urbanvault.in/spaces/banjara-hills', 'https://www.urbanvault.in/contact-us', 'https://www.urbanvault.in/spaces/office-space-jmd-megapolis-gurgaon', 'https://www.urbanvault.in/spaces/office-space-in-outer-ring-road', 'https://www.urbanvault.in/spaces/begumpet', 'https://www.urbanvault.in/spaces/office-space-in-indiranagar', 'https://www.urbanvault.in/spaces/office-space-in-koramangala', 'https://www.urbanvault.in/blogs/ease-of-doing-business-with-virtual-office', 'https://www.urbanvault.in/spaces/office-space-in-mg-road', 'https://www.urbanvault.in/spaces/office-space-in-whitefield', 'https://www.urbanvault.in/spaces/gachibowli', 'https://www.urbanvault.in/spaces/ameerpet', 'https://www.urbanvault.in/coworking-space-in-north-bangalore', 'https://www.urbanvault.in/?38849d0a_page=2', 'https://www.urbanvault.in/spaces/office-space-in-golf-course-road', 'https://www.urbanvault.in/spaces', 'https://www.urbanvault.in/spaces/office-space-in-electronic-city', 'https://www.urbanvault.in/spaces/office-space-for-rent-in-residency-road', 'https://www.urbanvault.in/office-spaces-in-gurgaon', 'https://www.urbanvault.in/spaces/office-space-in-mg-road-gurgaon', 'https://www.urbanvault.in/blogs', 'https://www.urbanvault.in/spaces/office-space-in-udyog-vihar', 'https://www.urbanvault.in/sitemap', 'https://www.urbanvault.in/refund-policy', 'https://www.urbanvault.in/spaces/office-space-near-huda-city-centre', 'https://www.urbanvault.in/blogs/the-psychology-of-office-design', 'https://www.urbanvault.in/spaces/office-space-in-parel', 'https://www.urbanvault.in/spaces/office-space-in-sarjapura', 'https://www.urbanvault.in/spaces/office-space-in-south-mumbai', 'https://www.urbanvault.in/spaces/jubilee-hills', 'https://www.urbanvault.in/coworking-space-in-cbd', 'https://www.urbanvault.in/spaces/kukatpalli', 'https://www.urbanvault.in/coworking-space-in-south-bangalore', 'https://www.urbanvault.in/spaces/office-space-in-jp-nagar', 'https://www.urbanvault.in/spaces/kphb', 'https://www.urbanvault.in/spaces/office-space-in-hsr-layout', 'https://www.urbanvault.in/blogs/8-expert-tips-for-renting-the-perfect-office-space-in-mg-road', 'https://www.urbanvault.in/spaces/hitech-city', 'https://www.urbanvault.in/spaces/office-space-sector-44-gurgaon']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-864d722de330>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_urls_from_domain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracted URLs: {urls}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mqa_system\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_langchain_qa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Ask some questions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-da16c78d65cf>\u001b[0m in \u001b[0;36mcreate_langchain_qa\u001b[0;34m(urls)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mvectorstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     retriever = vectorstore.as_retriever(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m         return cls.from_texts(\n\u001b[0m\u001b[1;32m    888\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mChroma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mChroma\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \"\"\"\n\u001b[0;32m--> 817\u001b[0;31m         chroma_collection = cls(\n\u001b[0m\u001b[1;32m    818\u001b[0m             \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0membedding_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;34m\"Could not import chromadb python package. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;34m\"Please install it with `pip install chromadb`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary LangChain components\n",
        "from langchain.agents import Tool, AgentExecutor, create_react_agent\n",
        "from langchain.tools import BaseTool\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import AgentType\n",
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# 1. Designing Goal-Oriented AI Agents with LangChain\n",
        "def create_goal_oriented_agent(goal_description, model_name=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    Create a goal-oriented agent using LangChain's components\n",
        "\n",
        "    Args:\n",
        "        goal_description: A string describing the agent's objective\n",
        "        model_name: The LLM model to use for the agent\n",
        "    \"\"\"\n",
        "    # Initialize the language model\n",
        "    llm = ChatOpenAI(model_name=model_name, temperature=0)\n",
        "\n",
        "    # Setup memory to maintain conversation context\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "    # Define custom prompt that includes the goal\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"You are an autonomous AI agent with the following goal: {goal}.\n",
        "\n",
        "        You have access to the following tools:\n",
        "        {tools}\n",
        "\n",
        "        Use the following format:\n",
        "\n",
        "        Thought: I need to analyze what needs to be done to achieve my goal\n",
        "        Action: the action to take, should be one of [{tool_names}]\n",
        "        Action Input: the input to the action\n",
        "        Observation: the result of the action\n",
        "        ... (repeat Thought/Action/Action Input/Observation as needed)\n",
        "        Thought: I've achieved the goal or made progress\n",
        "        Final Answer: the final output or response\n",
        "\n",
        "        Begin!\n",
        "\n",
        "        {chat_history}\n",
        "        Question: {input}\n",
        "        Thought: \"\"\"\n",
        "    )\n",
        "\n",
        "    # Define the tools available to the agent\n",
        "    search_tool = Tool(\n",
        "        name=\"Search\",\n",
        "        func=lambda x: f\"Results for: {x}\",\n",
        "        description=\"Useful for searching information on the internet\"\n",
        "    )\n",
        "\n",
        "    calculator_tool = Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=lambda x: eval(x),\n",
        "        description=\"Useful for performing mathematical calculations\"\n",
        "    )\n",
        "\n",
        "    tools = [search_tool, calculator_tool]\n",
        "\n",
        "    # Create the LangChain agent\n",
        "    agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "    # Create the agent executor\n",
        "    agent_executor = AgentExecutor(\n",
        "        agent=agent,\n",
        "        tools=tools,\n",
        "        memory=memory,\n",
        "        verbose=True,\n",
        "        handle_parsing_errors=True,\n",
        "    )\n",
        "\n",
        "    return agent_executor\n"
      ],
      "metadata": {
        "id": "ieLdAcaXosj0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "ef24b76d-67e1-4d92-9c37-7af844538077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'/usr/local/lib/python3.11/dist-packages/langchain/agents/agent_toolkits' is not in the subpath of '/usr/local/lib/python3.11/dist-packages/langchain_core' OR one path is relative and the other is absolute.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6802ac40e841>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConversationBufferMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_toolkits\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_python_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPythonREPLTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/agents/agent_toolkits/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;34m\"\"\"Get attr name.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDEPRECATED_AGENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mrelative_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_import_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mold_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"langchain.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mnew_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"langchain_experimental.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/path.py\u001b[0m in \u001b[0;36mas_import_path\u001b[0;34m(file, suffix, relative_to)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_relative_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/path.py\u001b[0m in \u001b[0;36mget_relative_path\u001b[0;34m(file, relative_to)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelative_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mrelative_to\u001b[0;34m(self, *other)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_abs_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mformatted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_parsed_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_drv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             raise ValueError(\"{!r} is not in the subpath of {!r}\"\n\u001b[0m\u001b[1;32m    731\u001b[0m                     \u001b[0;34m\" OR one path is relative and the other is absolute.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                              .format(str(self), str(formatted)))\n",
            "\u001b[0;31mValueError\u001b[0m: '/usr/local/lib/python3.11/dist-packages/langchain/agents/agent_toolkits' is not in the subpath of '/usr/local/lib/python3.11/dist-packages/langchain_core' OR one path is relative and the other is absolute."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai, langchain_agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7Qn_C-GGG85",
        "outputId": "1315a2a7-a2e4-4b54-dde6-cfaa6f62da15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'langchain_openai,': Expected end or semicolon (after name and no valid version specifier)\n",
            "    langchain_openai,\n",
            "                    ^\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "icmWnhhZGaBR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}